{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2712889,"sourceType":"datasetVersion","datasetId":1652987}],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/sarthaksshukla/cancer-images-classification?scriptVersionId=170078438\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"!pip install torchsummary","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-03T09:48:57.942183Z","iopub.execute_input":"2024-04-03T09:48:57.942487Z","iopub.status.idle":"2024-04-03T09:49:11.387287Z","shell.execute_reply.started":"2024-04-03T09:48:57.942461Z","shell.execute_reply":"2024-04-03T09:49:11.386278Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting torchsummary\n  Obtaining dependency information for torchsummary from https://files.pythonhosted.org/packages/7d/18/1474d06f721b86e6a9b9d7392ad68bed711a02f3b61ac43f13c719db50a6/torchsummary-1.5.1-py3-none-any.whl.metadata\n  Downloading torchsummary-1.5.1-py3-none-any.whl.metadata (296 bytes)\nDownloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\nInstalling collected packages: torchsummary\nSuccessfully installed torchsummary-1.5.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import os,random,shutil\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport pandas as pd\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms,datasets\nfrom fastprogress import master_bar,progress_bar\nfrom torchsummary import summary\nfrom tqdm import tqdm\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2024-04-03T09:49:11.38921Z","iopub.execute_input":"2024-04-03T09:49:11.389511Z","iopub.status.idle":"2024-04-03T09:49:11.399547Z","shell.execute_reply.started":"2024-04-03T09:49:11.389483Z","shell.execute_reply":"2024-04-03T09:49:11.398733Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() is True else \"cpu\"\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-03T09:49:11.400608Z","iopub.execute_input":"2024-04-03T09:49:11.400888Z","iopub.status.idle":"2024-04-03T09:49:11.433005Z","shell.execute_reply.started":"2024-04-03T09:49:11.400865Z","shell.execute_reply":"2024-04-03T09:49:11.431896Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Setting up the data paths","metadata":{}},{"cell_type":"code","source":"image_shape = (96,96)\nimage_size = (3,96,96)\nbatch_size = 32\nepochs = 30\nsteps_per_epoch = 1125","metadata":{"execution":{"iopub.status.busy":"2024-04-03T09:49:11.435968Z","iopub.execute_input":"2024-04-03T09:49:11.436461Z","iopub.status.idle":"2024-04-03T09:49:11.442001Z","shell.execute_reply.started":"2024-04-03T09:49:11.436434Z","shell.execute_reply":"2024-04-03T09:49:11.441136Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Setting up the directories for different classes","metadata":{}},{"cell_type":"code","source":"labels_document_path = \"/kaggle/input/hcd-cropped/train_labels.csv\"\nsource_path = \"/kaggle/input/hcd-cropped/train\"\ndestination_dataset_path = \"/kaggle/output/model_dataset\"\ntrain_path = os.path.join(destination_dataset_path,\"train\")\nvalid_path = os.path.join(destination_dataset_path,'valid')","metadata":{"execution":{"iopub.status.busy":"2024-04-03T09:49:11.443257Z","iopub.execute_input":"2024-04-03T09:49:11.443545Z","iopub.status.idle":"2024-04-03T09:49:11.450493Z","shell.execute_reply.started":"2024-04-03T09:49:11.443522Z","shell.execute_reply":"2024-04-03T09:49:11.449612Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def extract_labels_mapping(path):\n    mapping = {}\n    with open(path) as file:\n        for line in file.readlines()[1:]:\n            line = line.strip().split(\",\")\n            mapping[line[0]] = line[-1]\n    return mapping","metadata":{"execution":{"iopub.status.busy":"2024-04-03T09:49:11.451656Z","iopub.execute_input":"2024-04-03T09:49:11.452386Z","iopub.status.idle":"2024-04-03T09:49:11.459509Z","shell.execute_reply.started":"2024-04-03T09:49:11.452355Z","shell.execute_reply":"2024-04-03T09:49:11.458725Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"labels_mapping = extract_labels_mapping(labels_document_path)","metadata":{"execution":{"iopub.status.busy":"2024-04-03T09:49:11.460518Z","iopub.execute_input":"2024-04-03T09:49:11.460817Z","iopub.status.idle":"2024-04-03T09:49:11.805263Z","shell.execute_reply.started":"2024-04-03T09:49:11.460795Z","shell.execute_reply":"2024-04-03T09:49:11.804458Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"target_classes = sorted(list(set(labels_mapping.values())))\nprint(target_classes)","metadata":{"execution":{"iopub.status.busy":"2024-04-03T09:49:11.806292Z","iopub.execute_input":"2024-04-03T09:49:11.806545Z","iopub.status.idle":"2024-04-03T09:49:11.815133Z","shell.execute_reply.started":"2024-04-03T09:49:11.806523Z","shell.execute_reply":"2024-04-03T09:49:11.814141Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"['0', '1']\n","output_type":"stream"}]},{"cell_type":"code","source":"if os.path.exists(source_path) is False:\n    os.makedirs(destination_dataset_path)\n    os.mkdir(train_path)\n    os.mkdir(valid_path)","metadata":{"execution":{"iopub.status.busy":"2024-04-03T09:49:11.816403Z","iopub.execute_input":"2024-04-03T09:49:11.816993Z","iopub.status.idle":"2024-04-03T09:49:11.824706Z","shell.execute_reply.started":"2024-04-03T09:49:11.816961Z","shell.execute_reply":"2024-04-03T09:49:11.823945Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"for target in target_classes:\n    os.makedirs(os.path.join(train_path,target))\n    os.makedirs(os.path.join(valid_path,target))","metadata":{"execution":{"iopub.status.busy":"2024-04-03T09:49:11.825788Z","iopub.execute_input":"2024-04-03T09:49:11.826136Z","iopub.status.idle":"2024-04-03T09:49:11.833431Z","shell.execute_reply.started":"2024-04-03T09:49:11.826082Z","shell.execute_reply":"2024-04-03T09:49:11.832738Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def convert_tiff_to_png(tiff_file_path,destination_dir):\n    file_name = os.path.basename(tiff_file_path)\n    png_path = os.path.join(destination_dir,os.path.splitext(file_name)[0] + \".png\")\n    image = Image.open(tiff_file_path)\n    image.save(png_path)","metadata":{"execution":{"iopub.status.busy":"2024-04-03T09:49:11.837613Z","iopub.execute_input":"2024-04-03T09:49:11.83789Z","iopub.status.idle":"2024-04-03T09:49:11.845296Z","shell.execute_reply.started":"2024-04-03T09:49:11.837868Z","shell.execute_reply":"2024-04-03T09:49:11.844478Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def construct_dataset(source_path,destination_path,mapping,num_images):\n    image_paths = random.sample(os.listdir(source_path),num_images)\n    for i in tqdm(range(len(image_paths))):\n        image_path = image_paths[i]\n        image_file_path = os.path.join(source_path,image_path)\n        image_file_name = image_path.split(\".\")[0]\n        cpy_path = os.path.join(destination_path,mapping[image_file_name])\n        convert_tiff_to_png(tiff_file_path = image_file_path,\n                           destination_dir = cpy_path)","metadata":{"execution":{"iopub.status.busy":"2024-04-03T09:49:11.846292Z","iopub.execute_input":"2024-04-03T09:49:11.846545Z","iopub.status.idle":"2024-04-03T09:49:11.854388Z","shell.execute_reply.started":"2024-04-03T09:49:11.846506Z","shell.execute_reply":"2024-04-03T09:49:11.853547Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Constructing the datasets and dataloader objects","metadata":{}},{"cell_type":"code","source":"construct_dataset(\n    source_path = source_path,destination_path = train_path,\n    mapping = labels_mapping,num_images = 50000\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-03T09:49:11.855389Z","iopub.execute_input":"2024-04-03T09:49:11.855677Z","iopub.status.idle":"2024-04-03T09:53:02.3969Z","shell.execute_reply.started":"2024-04-03T09:49:11.855652Z","shell.execute_reply":"2024-04-03T09:53:02.395966Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"100%|██████████| 50000/50000 [03:48<00:00, 218.90it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"construct_dataset(source_path = source_path,destination_path = valid_path,\n                 mapping = labels_mapping,num_images = 20000)","metadata":{"execution":{"iopub.status.busy":"2024-04-03T09:53:02.398132Z","iopub.execute_input":"2024-04-03T09:53:02.39841Z","iopub.status.idle":"2024-04-03T09:54:18.558702Z","shell.execute_reply.started":"2024-04-03T09:53:02.398386Z","shell.execute_reply":"2024-04-03T09:54:18.557824Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"100%|██████████| 20000/20000 [01:15<00:00, 263.28it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"train_transforms = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean = [0.485, 0.456, 0.406],\n        std = [0.229, 0.224, 0.225]\n    ),\n    transforms.Resize(image_shape,antialias = True),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip()\n])\n\nvalid_transforms = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean = [0.485, 0.456, 0.406],\n        std = [0.229, 0.224, 0.225]\n    ),\n    transforms.Resize(image_shape,antialias = True)\n])","metadata":{"execution":{"iopub.status.busy":"2024-04-03T09:54:18.559988Z","iopub.execute_input":"2024-04-03T09:54:18.560588Z","iopub.status.idle":"2024-04-03T09:54:18.567206Z","shell.execute_reply.started":"2024-04-03T09:54:18.560553Z","shell.execute_reply":"2024-04-03T09:54:18.566378Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"train_dataset = datasets.ImageFolder(root = train_path,transform = train_transforms)\nvalid_dataset = datasets.ImageFolder(root = valid_path,transform = valid_transforms)","metadata":{"execution":{"iopub.status.busy":"2024-04-03T09:54:18.568294Z","iopub.execute_input":"2024-04-03T09:54:18.568894Z","iopub.status.idle":"2024-04-03T09:54:18.905572Z","shell.execute_reply.started":"2024-04-03T09:54:18.568861Z","shell.execute_reply":"2024-04-03T09:54:18.904802Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"train_dataloader = DataLoader(dataset = train_dataset,batch_size = batch_size,shuffle = True,\n                             pin_memory = True,drop_last = True)\n\nvalid_dataloader = DataLoader(dataset = valid_dataset,batch_size = batch_size,shuffle = True,\n                             pin_memory = True,drop_last = True)","metadata":{"execution":{"iopub.status.busy":"2024-04-03T09:54:18.906682Z","iopub.execute_input":"2024-04-03T09:54:18.906977Z","iopub.status.idle":"2024-04-03T09:54:18.912244Z","shell.execute_reply.started":"2024-04-03T09:54:18.906944Z","shell.execute_reply":"2024-04-03T09:54:18.91137Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# Building the model","metadata":{}},{"cell_type":"code","source":"class Conv(nn.Module):\n    def __init__(self,in_channels,out_channels,**kwargs):\n        super().__init__(**kwargs)\n        self.__model = nn.Sequential(*[\n            nn.Conv2d(in_channels,out_channels,kernel_size = 3,stride = 1,padding = 1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(),\n        ])\n    \n    def forward(self,inputs):\n        return self.__model(inputs)","metadata":{"execution":{"iopub.status.busy":"2024-04-03T09:54:18.913509Z","iopub.execute_input":"2024-04-03T09:54:18.913774Z","iopub.status.idle":"2024-04-03T09:54:18.922476Z","shell.execute_reply.started":"2024-04-03T09:54:18.913751Z","shell.execute_reply":"2024-04-03T09:54:18.921555Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"class ConvStack(nn.Module):\n    def __init__(self,in_channels,out_channels,n_conv = 4,**kwargs):\n        super().__init__(**kwargs)\n        self.__model = nn.Sequential(*[\n            *[Conv(in_channels = in_channels,out_channels = in_channels) for _ in range(n_conv - 1)],\n            Conv(in_channels = in_channels,out_channels = out_channels),\n        ])\n    \n    def forward(self,inputs):\n        return self.__model(inputs)","metadata":{"execution":{"iopub.status.busy":"2024-04-03T09:54:18.923549Z","iopub.execute_input":"2024-04-03T09:54:18.923808Z","iopub.status.idle":"2024-04-03T09:54:18.934673Z","shell.execute_reply.started":"2024-04-03T09:54:18.923785Z","shell.execute_reply":"2024-04-03T09:54:18.933914Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"class ResnetLayer(nn.Module):\n    def __init__(self,channels,num_layers = 4,n_conv = 4,**kwargs):\n        super().__init__(**kwargs)\n        self.__model = nn.Sequential(*[\n            ConvStack(in_channels = channels,out_channels = channels,n_conv = n_conv)\n            for _ in range(num_layers)\n        ])\n    \n    def forward(self,inputs):\n        output = self.__model(inputs)\n        return F.relu(inputs + output)","metadata":{"execution":{"iopub.status.busy":"2024-04-03T09:54:18.935613Z","iopub.execute_input":"2024-04-03T09:54:18.935874Z","iopub.status.idle":"2024-04-03T09:54:18.943805Z","shell.execute_reply.started":"2024-04-03T09:54:18.93585Z","shell.execute_reply":"2024-04-03T09:54:18.943076Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"class Pooling(nn.Module):\n    def __init__(self,channels,**kwargs):\n        super().__init__(**kwargs)\n        self.__model = nn.Sequential(*[\n            nn.Conv2d(channels,2 * channels,kernel_size = 3,stride = 1,padding = 1),\n            nn.AvgPool2d(kernel_size = 2,stride = 2),\n            nn.BatchNorm2d(channels * 2),\n            nn.ReLU(),\n        ])\n    \n    def forward(self,inputs):\n        return self.__model(inputs)","metadata":{"execution":{"iopub.status.busy":"2024-04-03T09:54:18.944768Z","iopub.execute_input":"2024-04-03T09:54:18.944993Z","iopub.status.idle":"2024-04-03T09:54:18.952547Z","shell.execute_reply.started":"2024-04-03T09:54:18.944969Z","shell.execute_reply":"2024-04-03T09:54:18.951844Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"class FullyConnected(nn.Module):\n    def __init__(self,channels,num_classes,units = 4096,**kwargs):\n        super().__init__(**kwargs)\n        self.__model = nn.Sequential(*[\n            nn.Flatten(),\n            nn.Linear(channels,units),\n            nn.ReLU(),\n            nn.Linear(units,units),\n            nn.ReLU(),\n            nn.Linear(units,num_classes),\n            nn.Softmax(dim = -1)\n        ])\n    \n    def forward(self,inputs):\n        return self.__model(inputs)","metadata":{"execution":{"iopub.status.busy":"2024-04-03T09:54:18.953589Z","iopub.execute_input":"2024-04-03T09:54:18.954336Z","iopub.status.idle":"2024-04-03T09:54:18.962065Z","shell.execute_reply.started":"2024-04-03T09:54:18.954305Z","shell.execute_reply":"2024-04-03T09:54:18.961381Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"class Resnet(nn.Module):\n    def __init__(self,image_shape,num_classes,n_conv = 4,units = 4096,num_layers = 4,**kwargs):\n        super().__init__(**kwargs)\n        channels,height,width = image_shape\n        self.__model = []\n        self.__input = nn.Sequential(*[\n            Conv(in_channels = channels,out_channels = 8),\n        ])\n        channels = 8\n        while height > 1:\n            self.__model.append(ResnetLayer(channels = channels,num_layers = num_layers,n_conv = n_conv))\n            self.__model.append(Pooling(channels = channels))\n            height //= 2\n            width //= 2\n            channels *= 2\n        \n        self.__model.append(FullyConnected(channels = channels,num_classes = num_classes,units = units))\n        self.__model = nn.Sequential(*self.__model)\n    \n    def forward(self,inputs):\n        output = self.__input(inputs)\n        return self.__model(output)","metadata":{"execution":{"iopub.status.busy":"2024-04-03T09:54:18.963262Z","iopub.execute_input":"2024-04-03T09:54:18.963538Z","iopub.status.idle":"2024-04-03T09:54:18.974745Z","shell.execute_reply.started":"2024-04-03T09:54:18.963515Z","shell.execute_reply":"2024-04-03T09:54:18.973986Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"model = Resnet(image_shape = image_size,num_classes = 2)","metadata":{"execution":{"iopub.status.busy":"2024-04-03T09:54:18.975769Z","iopub.execute_input":"2024-04-03T09:54:18.976507Z","iopub.status.idle":"2024-04-03T09:54:19.323038Z","shell.execute_reply.started":"2024-04-03T09:54:18.976473Z","shell.execute_reply":"2024-04-03T09:54:19.322026Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"model = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-03T09:54:19.324243Z","iopub.execute_input":"2024-04-03T09:54:19.324539Z","iopub.status.idle":"2024-04-03T09:54:19.533649Z","shell.execute_reply.started":"2024-04-03T09:54:19.324514Z","shell.execute_reply":"2024-04-03T09:54:19.53272Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"summary(model,image_size)","metadata":{"execution":{"iopub.status.busy":"2024-04-03T09:54:19.534862Z","iopub.execute_input":"2024-04-03T09:54:19.535599Z","iopub.status.idle":"2024-04-03T09:54:20.21982Z","shell.execute_reply.started":"2024-04-03T09:54:19.53557Z","shell.execute_reply":"2024-04-03T09:54:20.218913Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1            [-1, 8, 96, 96]             224\n       BatchNorm2d-2            [-1, 8, 96, 96]              16\n              ReLU-3            [-1, 8, 96, 96]               0\n              Conv-4            [-1, 8, 96, 96]               0\n            Conv2d-5            [-1, 8, 96, 96]             584\n       BatchNorm2d-6            [-1, 8, 96, 96]              16\n              ReLU-7            [-1, 8, 96, 96]               0\n              Conv-8            [-1, 8, 96, 96]               0\n            Conv2d-9            [-1, 8, 96, 96]             584\n      BatchNorm2d-10            [-1, 8, 96, 96]              16\n             ReLU-11            [-1, 8, 96, 96]               0\n             Conv-12            [-1, 8, 96, 96]               0\n           Conv2d-13            [-1, 8, 96, 96]             584\n      BatchNorm2d-14            [-1, 8, 96, 96]              16\n             ReLU-15            [-1, 8, 96, 96]               0\n             Conv-16            [-1, 8, 96, 96]               0\n           Conv2d-17            [-1, 8, 96, 96]             584\n      BatchNorm2d-18            [-1, 8, 96, 96]              16\n             ReLU-19            [-1, 8, 96, 96]               0\n             Conv-20            [-1, 8, 96, 96]               0\n        ConvStack-21            [-1, 8, 96, 96]               0\n           Conv2d-22            [-1, 8, 96, 96]             584\n      BatchNorm2d-23            [-1, 8, 96, 96]              16\n             ReLU-24            [-1, 8, 96, 96]               0\n             Conv-25            [-1, 8, 96, 96]               0\n           Conv2d-26            [-1, 8, 96, 96]             584\n      BatchNorm2d-27            [-1, 8, 96, 96]              16\n             ReLU-28            [-1, 8, 96, 96]               0\n             Conv-29            [-1, 8, 96, 96]               0\n           Conv2d-30            [-1, 8, 96, 96]             584\n      BatchNorm2d-31            [-1, 8, 96, 96]              16\n             ReLU-32            [-1, 8, 96, 96]               0\n             Conv-33            [-1, 8, 96, 96]               0\n           Conv2d-34            [-1, 8, 96, 96]             584\n      BatchNorm2d-35            [-1, 8, 96, 96]              16\n             ReLU-36            [-1, 8, 96, 96]               0\n             Conv-37            [-1, 8, 96, 96]               0\n        ConvStack-38            [-1, 8, 96, 96]               0\n           Conv2d-39            [-1, 8, 96, 96]             584\n      BatchNorm2d-40            [-1, 8, 96, 96]              16\n             ReLU-41            [-1, 8, 96, 96]               0\n             Conv-42            [-1, 8, 96, 96]               0\n           Conv2d-43            [-1, 8, 96, 96]             584\n      BatchNorm2d-44            [-1, 8, 96, 96]              16\n             ReLU-45            [-1, 8, 96, 96]               0\n             Conv-46            [-1, 8, 96, 96]               0\n           Conv2d-47            [-1, 8, 96, 96]             584\n      BatchNorm2d-48            [-1, 8, 96, 96]              16\n             ReLU-49            [-1, 8, 96, 96]               0\n             Conv-50            [-1, 8, 96, 96]               0\n           Conv2d-51            [-1, 8, 96, 96]             584\n      BatchNorm2d-52            [-1, 8, 96, 96]              16\n             ReLU-53            [-1, 8, 96, 96]               0\n             Conv-54            [-1, 8, 96, 96]               0\n        ConvStack-55            [-1, 8, 96, 96]               0\n           Conv2d-56            [-1, 8, 96, 96]             584\n      BatchNorm2d-57            [-1, 8, 96, 96]              16\n             ReLU-58            [-1, 8, 96, 96]               0\n             Conv-59            [-1, 8, 96, 96]               0\n           Conv2d-60            [-1, 8, 96, 96]             584\n      BatchNorm2d-61            [-1, 8, 96, 96]              16\n             ReLU-62            [-1, 8, 96, 96]               0\n             Conv-63            [-1, 8, 96, 96]               0\n           Conv2d-64            [-1, 8, 96, 96]             584\n      BatchNorm2d-65            [-1, 8, 96, 96]              16\n             ReLU-66            [-1, 8, 96, 96]               0\n             Conv-67            [-1, 8, 96, 96]               0\n           Conv2d-68            [-1, 8, 96, 96]             584\n      BatchNorm2d-69            [-1, 8, 96, 96]              16\n             ReLU-70            [-1, 8, 96, 96]               0\n             Conv-71            [-1, 8, 96, 96]               0\n        ConvStack-72            [-1, 8, 96, 96]               0\n      ResnetLayer-73            [-1, 8, 96, 96]               0\n           Conv2d-74           [-1, 16, 96, 96]           1,168\n        AvgPool2d-75           [-1, 16, 48, 48]               0\n      BatchNorm2d-76           [-1, 16, 48, 48]              32\n             ReLU-77           [-1, 16, 48, 48]               0\n          Pooling-78           [-1, 16, 48, 48]               0\n           Conv2d-79           [-1, 16, 48, 48]           2,320\n      BatchNorm2d-80           [-1, 16, 48, 48]              32\n             ReLU-81           [-1, 16, 48, 48]               0\n             Conv-82           [-1, 16, 48, 48]               0\n           Conv2d-83           [-1, 16, 48, 48]           2,320\n      BatchNorm2d-84           [-1, 16, 48, 48]              32\n             ReLU-85           [-1, 16, 48, 48]               0\n             Conv-86           [-1, 16, 48, 48]               0\n           Conv2d-87           [-1, 16, 48, 48]           2,320\n      BatchNorm2d-88           [-1, 16, 48, 48]              32\n             ReLU-89           [-1, 16, 48, 48]               0\n             Conv-90           [-1, 16, 48, 48]               0\n           Conv2d-91           [-1, 16, 48, 48]           2,320\n      BatchNorm2d-92           [-1, 16, 48, 48]              32\n             ReLU-93           [-1, 16, 48, 48]               0\n             Conv-94           [-1, 16, 48, 48]               0\n        ConvStack-95           [-1, 16, 48, 48]               0\n           Conv2d-96           [-1, 16, 48, 48]           2,320\n      BatchNorm2d-97           [-1, 16, 48, 48]              32\n             ReLU-98           [-1, 16, 48, 48]               0\n             Conv-99           [-1, 16, 48, 48]               0\n          Conv2d-100           [-1, 16, 48, 48]           2,320\n     BatchNorm2d-101           [-1, 16, 48, 48]              32\n            ReLU-102           [-1, 16, 48, 48]               0\n            Conv-103           [-1, 16, 48, 48]               0\n          Conv2d-104           [-1, 16, 48, 48]           2,320\n     BatchNorm2d-105           [-1, 16, 48, 48]              32\n            ReLU-106           [-1, 16, 48, 48]               0\n            Conv-107           [-1, 16, 48, 48]               0\n          Conv2d-108           [-1, 16, 48, 48]           2,320\n     BatchNorm2d-109           [-1, 16, 48, 48]              32\n            ReLU-110           [-1, 16, 48, 48]               0\n            Conv-111           [-1, 16, 48, 48]               0\n       ConvStack-112           [-1, 16, 48, 48]               0\n          Conv2d-113           [-1, 16, 48, 48]           2,320\n     BatchNorm2d-114           [-1, 16, 48, 48]              32\n            ReLU-115           [-1, 16, 48, 48]               0\n            Conv-116           [-1, 16, 48, 48]               0\n          Conv2d-117           [-1, 16, 48, 48]           2,320\n     BatchNorm2d-118           [-1, 16, 48, 48]              32\n            ReLU-119           [-1, 16, 48, 48]               0\n            Conv-120           [-1, 16, 48, 48]               0\n          Conv2d-121           [-1, 16, 48, 48]           2,320\n     BatchNorm2d-122           [-1, 16, 48, 48]              32\n            ReLU-123           [-1, 16, 48, 48]               0\n            Conv-124           [-1, 16, 48, 48]               0\n          Conv2d-125           [-1, 16, 48, 48]           2,320\n     BatchNorm2d-126           [-1, 16, 48, 48]              32\n            ReLU-127           [-1, 16, 48, 48]               0\n            Conv-128           [-1, 16, 48, 48]               0\n       ConvStack-129           [-1, 16, 48, 48]               0\n          Conv2d-130           [-1, 16, 48, 48]           2,320\n     BatchNorm2d-131           [-1, 16, 48, 48]              32\n            ReLU-132           [-1, 16, 48, 48]               0\n            Conv-133           [-1, 16, 48, 48]               0\n          Conv2d-134           [-1, 16, 48, 48]           2,320\n     BatchNorm2d-135           [-1, 16, 48, 48]              32\n            ReLU-136           [-1, 16, 48, 48]               0\n            Conv-137           [-1, 16, 48, 48]               0\n          Conv2d-138           [-1, 16, 48, 48]           2,320\n     BatchNorm2d-139           [-1, 16, 48, 48]              32\n            ReLU-140           [-1, 16, 48, 48]               0\n            Conv-141           [-1, 16, 48, 48]               0\n          Conv2d-142           [-1, 16, 48, 48]           2,320\n     BatchNorm2d-143           [-1, 16, 48, 48]              32\n            ReLU-144           [-1, 16, 48, 48]               0\n            Conv-145           [-1, 16, 48, 48]               0\n       ConvStack-146           [-1, 16, 48, 48]               0\n     ResnetLayer-147           [-1, 16, 48, 48]               0\n          Conv2d-148           [-1, 32, 48, 48]           4,640\n       AvgPool2d-149           [-1, 32, 24, 24]               0\n     BatchNorm2d-150           [-1, 32, 24, 24]              64\n            ReLU-151           [-1, 32, 24, 24]               0\n         Pooling-152           [-1, 32, 24, 24]               0\n          Conv2d-153           [-1, 32, 24, 24]           9,248\n     BatchNorm2d-154           [-1, 32, 24, 24]              64\n            ReLU-155           [-1, 32, 24, 24]               0\n            Conv-156           [-1, 32, 24, 24]               0\n          Conv2d-157           [-1, 32, 24, 24]           9,248\n     BatchNorm2d-158           [-1, 32, 24, 24]              64\n            ReLU-159           [-1, 32, 24, 24]               0\n            Conv-160           [-1, 32, 24, 24]               0\n          Conv2d-161           [-1, 32, 24, 24]           9,248\n     BatchNorm2d-162           [-1, 32, 24, 24]              64\n            ReLU-163           [-1, 32, 24, 24]               0\n            Conv-164           [-1, 32, 24, 24]               0\n          Conv2d-165           [-1, 32, 24, 24]           9,248\n     BatchNorm2d-166           [-1, 32, 24, 24]              64\n            ReLU-167           [-1, 32, 24, 24]               0\n            Conv-168           [-1, 32, 24, 24]               0\n       ConvStack-169           [-1, 32, 24, 24]               0\n          Conv2d-170           [-1, 32, 24, 24]           9,248\n     BatchNorm2d-171           [-1, 32, 24, 24]              64\n            ReLU-172           [-1, 32, 24, 24]               0\n            Conv-173           [-1, 32, 24, 24]               0\n          Conv2d-174           [-1, 32, 24, 24]           9,248\n     BatchNorm2d-175           [-1, 32, 24, 24]              64\n            ReLU-176           [-1, 32, 24, 24]               0\n            Conv-177           [-1, 32, 24, 24]               0\n          Conv2d-178           [-1, 32, 24, 24]           9,248\n     BatchNorm2d-179           [-1, 32, 24, 24]              64\n            ReLU-180           [-1, 32, 24, 24]               0\n            Conv-181           [-1, 32, 24, 24]               0\n          Conv2d-182           [-1, 32, 24, 24]           9,248\n     BatchNorm2d-183           [-1, 32, 24, 24]              64\n            ReLU-184           [-1, 32, 24, 24]               0\n            Conv-185           [-1, 32, 24, 24]               0\n       ConvStack-186           [-1, 32, 24, 24]               0\n          Conv2d-187           [-1, 32, 24, 24]           9,248\n     BatchNorm2d-188           [-1, 32, 24, 24]              64\n            ReLU-189           [-1, 32, 24, 24]               0\n            Conv-190           [-1, 32, 24, 24]               0\n          Conv2d-191           [-1, 32, 24, 24]           9,248\n     BatchNorm2d-192           [-1, 32, 24, 24]              64\n            ReLU-193           [-1, 32, 24, 24]               0\n            Conv-194           [-1, 32, 24, 24]               0\n          Conv2d-195           [-1, 32, 24, 24]           9,248\n     BatchNorm2d-196           [-1, 32, 24, 24]              64\n            ReLU-197           [-1, 32, 24, 24]               0\n            Conv-198           [-1, 32, 24, 24]               0\n          Conv2d-199           [-1, 32, 24, 24]           9,248\n     BatchNorm2d-200           [-1, 32, 24, 24]              64\n            ReLU-201           [-1, 32, 24, 24]               0\n            Conv-202           [-1, 32, 24, 24]               0\n       ConvStack-203           [-1, 32, 24, 24]               0\n          Conv2d-204           [-1, 32, 24, 24]           9,248\n     BatchNorm2d-205           [-1, 32, 24, 24]              64\n            ReLU-206           [-1, 32, 24, 24]               0\n            Conv-207           [-1, 32, 24, 24]               0\n          Conv2d-208           [-1, 32, 24, 24]           9,248\n     BatchNorm2d-209           [-1, 32, 24, 24]              64\n            ReLU-210           [-1, 32, 24, 24]               0\n            Conv-211           [-1, 32, 24, 24]               0\n          Conv2d-212           [-1, 32, 24, 24]           9,248\n     BatchNorm2d-213           [-1, 32, 24, 24]              64\n            ReLU-214           [-1, 32, 24, 24]               0\n            Conv-215           [-1, 32, 24, 24]               0\n          Conv2d-216           [-1, 32, 24, 24]           9,248\n     BatchNorm2d-217           [-1, 32, 24, 24]              64\n            ReLU-218           [-1, 32, 24, 24]               0\n            Conv-219           [-1, 32, 24, 24]               0\n       ConvStack-220           [-1, 32, 24, 24]               0\n     ResnetLayer-221           [-1, 32, 24, 24]               0\n          Conv2d-222           [-1, 64, 24, 24]          18,496\n       AvgPool2d-223           [-1, 64, 12, 12]               0\n     BatchNorm2d-224           [-1, 64, 12, 12]             128\n            ReLU-225           [-1, 64, 12, 12]               0\n         Pooling-226           [-1, 64, 12, 12]               0\n          Conv2d-227           [-1, 64, 12, 12]          36,928\n     BatchNorm2d-228           [-1, 64, 12, 12]             128\n            ReLU-229           [-1, 64, 12, 12]               0\n            Conv-230           [-1, 64, 12, 12]               0\n          Conv2d-231           [-1, 64, 12, 12]          36,928\n     BatchNorm2d-232           [-1, 64, 12, 12]             128\n            ReLU-233           [-1, 64, 12, 12]               0\n            Conv-234           [-1, 64, 12, 12]               0\n          Conv2d-235           [-1, 64, 12, 12]          36,928\n     BatchNorm2d-236           [-1, 64, 12, 12]             128\n            ReLU-237           [-1, 64, 12, 12]               0\n            Conv-238           [-1, 64, 12, 12]               0\n          Conv2d-239           [-1, 64, 12, 12]          36,928\n     BatchNorm2d-240           [-1, 64, 12, 12]             128\n            ReLU-241           [-1, 64, 12, 12]               0\n            Conv-242           [-1, 64, 12, 12]               0\n       ConvStack-243           [-1, 64, 12, 12]               0\n          Conv2d-244           [-1, 64, 12, 12]          36,928\n     BatchNorm2d-245           [-1, 64, 12, 12]             128\n            ReLU-246           [-1, 64, 12, 12]               0\n            Conv-247           [-1, 64, 12, 12]               0\n          Conv2d-248           [-1, 64, 12, 12]          36,928\n     BatchNorm2d-249           [-1, 64, 12, 12]             128\n            ReLU-250           [-1, 64, 12, 12]               0\n            Conv-251           [-1, 64, 12, 12]               0\n          Conv2d-252           [-1, 64, 12, 12]          36,928\n     BatchNorm2d-253           [-1, 64, 12, 12]             128\n            ReLU-254           [-1, 64, 12, 12]               0\n            Conv-255           [-1, 64, 12, 12]               0\n          Conv2d-256           [-1, 64, 12, 12]          36,928\n     BatchNorm2d-257           [-1, 64, 12, 12]             128\n            ReLU-258           [-1, 64, 12, 12]               0\n            Conv-259           [-1, 64, 12, 12]               0\n       ConvStack-260           [-1, 64, 12, 12]               0\n          Conv2d-261           [-1, 64, 12, 12]          36,928\n     BatchNorm2d-262           [-1, 64, 12, 12]             128\n            ReLU-263           [-1, 64, 12, 12]               0\n            Conv-264           [-1, 64, 12, 12]               0\n          Conv2d-265           [-1, 64, 12, 12]          36,928\n     BatchNorm2d-266           [-1, 64, 12, 12]             128\n            ReLU-267           [-1, 64, 12, 12]               0\n            Conv-268           [-1, 64, 12, 12]               0\n          Conv2d-269           [-1, 64, 12, 12]          36,928\n     BatchNorm2d-270           [-1, 64, 12, 12]             128\n            ReLU-271           [-1, 64, 12, 12]               0\n            Conv-272           [-1, 64, 12, 12]               0\n          Conv2d-273           [-1, 64, 12, 12]          36,928\n     BatchNorm2d-274           [-1, 64, 12, 12]             128\n            ReLU-275           [-1, 64, 12, 12]               0\n            Conv-276           [-1, 64, 12, 12]               0\n       ConvStack-277           [-1, 64, 12, 12]               0\n          Conv2d-278           [-1, 64, 12, 12]          36,928\n     BatchNorm2d-279           [-1, 64, 12, 12]             128\n            ReLU-280           [-1, 64, 12, 12]               0\n            Conv-281           [-1, 64, 12, 12]               0\n          Conv2d-282           [-1, 64, 12, 12]          36,928\n     BatchNorm2d-283           [-1, 64, 12, 12]             128\n            ReLU-284           [-1, 64, 12, 12]               0\n            Conv-285           [-1, 64, 12, 12]               0\n          Conv2d-286           [-1, 64, 12, 12]          36,928\n     BatchNorm2d-287           [-1, 64, 12, 12]             128\n            ReLU-288           [-1, 64, 12, 12]               0\n            Conv-289           [-1, 64, 12, 12]               0\n          Conv2d-290           [-1, 64, 12, 12]          36,928\n     BatchNorm2d-291           [-1, 64, 12, 12]             128\n            ReLU-292           [-1, 64, 12, 12]               0\n            Conv-293           [-1, 64, 12, 12]               0\n       ConvStack-294           [-1, 64, 12, 12]               0\n     ResnetLayer-295           [-1, 64, 12, 12]               0\n          Conv2d-296          [-1, 128, 12, 12]          73,856\n       AvgPool2d-297            [-1, 128, 6, 6]               0\n     BatchNorm2d-298            [-1, 128, 6, 6]             256\n            ReLU-299            [-1, 128, 6, 6]               0\n         Pooling-300            [-1, 128, 6, 6]               0\n          Conv2d-301            [-1, 128, 6, 6]         147,584\n     BatchNorm2d-302            [-1, 128, 6, 6]             256\n            ReLU-303            [-1, 128, 6, 6]               0\n            Conv-304            [-1, 128, 6, 6]               0\n          Conv2d-305            [-1, 128, 6, 6]         147,584\n     BatchNorm2d-306            [-1, 128, 6, 6]             256\n            ReLU-307            [-1, 128, 6, 6]               0\n            Conv-308            [-1, 128, 6, 6]               0\n          Conv2d-309            [-1, 128, 6, 6]         147,584\n     BatchNorm2d-310            [-1, 128, 6, 6]             256\n            ReLU-311            [-1, 128, 6, 6]               0\n            Conv-312            [-1, 128, 6, 6]               0\n          Conv2d-313            [-1, 128, 6, 6]         147,584\n     BatchNorm2d-314            [-1, 128, 6, 6]             256\n            ReLU-315            [-1, 128, 6, 6]               0\n            Conv-316            [-1, 128, 6, 6]               0\n       ConvStack-317            [-1, 128, 6, 6]               0\n          Conv2d-318            [-1, 128, 6, 6]         147,584\n     BatchNorm2d-319            [-1, 128, 6, 6]             256\n            ReLU-320            [-1, 128, 6, 6]               0\n            Conv-321            [-1, 128, 6, 6]               0\n          Conv2d-322            [-1, 128, 6, 6]         147,584\n     BatchNorm2d-323            [-1, 128, 6, 6]             256\n            ReLU-324            [-1, 128, 6, 6]               0\n            Conv-325            [-1, 128, 6, 6]               0\n          Conv2d-326            [-1, 128, 6, 6]         147,584\n     BatchNorm2d-327            [-1, 128, 6, 6]             256\n            ReLU-328            [-1, 128, 6, 6]               0\n            Conv-329            [-1, 128, 6, 6]               0\n          Conv2d-330            [-1, 128, 6, 6]         147,584\n     BatchNorm2d-331            [-1, 128, 6, 6]             256\n            ReLU-332            [-1, 128, 6, 6]               0\n            Conv-333            [-1, 128, 6, 6]               0\n       ConvStack-334            [-1, 128, 6, 6]               0\n          Conv2d-335            [-1, 128, 6, 6]         147,584\n     BatchNorm2d-336            [-1, 128, 6, 6]             256\n            ReLU-337            [-1, 128, 6, 6]               0\n            Conv-338            [-1, 128, 6, 6]               0\n          Conv2d-339            [-1, 128, 6, 6]         147,584\n     BatchNorm2d-340            [-1, 128, 6, 6]             256\n            ReLU-341            [-1, 128, 6, 6]               0\n            Conv-342            [-1, 128, 6, 6]               0\n          Conv2d-343            [-1, 128, 6, 6]         147,584\n     BatchNorm2d-344            [-1, 128, 6, 6]             256\n            ReLU-345            [-1, 128, 6, 6]               0\n            Conv-346            [-1, 128, 6, 6]               0\n          Conv2d-347            [-1, 128, 6, 6]         147,584\n     BatchNorm2d-348            [-1, 128, 6, 6]             256\n            ReLU-349            [-1, 128, 6, 6]               0\n            Conv-350            [-1, 128, 6, 6]               0\n       ConvStack-351            [-1, 128, 6, 6]               0\n          Conv2d-352            [-1, 128, 6, 6]         147,584\n     BatchNorm2d-353            [-1, 128, 6, 6]             256\n            ReLU-354            [-1, 128, 6, 6]               0\n            Conv-355            [-1, 128, 6, 6]               0\n          Conv2d-356            [-1, 128, 6, 6]         147,584\n     BatchNorm2d-357            [-1, 128, 6, 6]             256\n            ReLU-358            [-1, 128, 6, 6]               0\n            Conv-359            [-1, 128, 6, 6]               0\n          Conv2d-360            [-1, 128, 6, 6]         147,584\n     BatchNorm2d-361            [-1, 128, 6, 6]             256\n            ReLU-362            [-1, 128, 6, 6]               0\n            Conv-363            [-1, 128, 6, 6]               0\n          Conv2d-364            [-1, 128, 6, 6]         147,584\n     BatchNorm2d-365            [-1, 128, 6, 6]             256\n            ReLU-366            [-1, 128, 6, 6]               0\n            Conv-367            [-1, 128, 6, 6]               0\n       ConvStack-368            [-1, 128, 6, 6]               0\n     ResnetLayer-369            [-1, 128, 6, 6]               0\n          Conv2d-370            [-1, 256, 6, 6]         295,168\n       AvgPool2d-371            [-1, 256, 3, 3]               0\n     BatchNorm2d-372            [-1, 256, 3, 3]             512\n            ReLU-373            [-1, 256, 3, 3]               0\n         Pooling-374            [-1, 256, 3, 3]               0\n          Conv2d-375            [-1, 256, 3, 3]         590,080\n     BatchNorm2d-376            [-1, 256, 3, 3]             512\n            ReLU-377            [-1, 256, 3, 3]               0\n            Conv-378            [-1, 256, 3, 3]               0\n          Conv2d-379            [-1, 256, 3, 3]         590,080\n     BatchNorm2d-380            [-1, 256, 3, 3]             512\n            ReLU-381            [-1, 256, 3, 3]               0\n            Conv-382            [-1, 256, 3, 3]               0\n          Conv2d-383            [-1, 256, 3, 3]         590,080\n     BatchNorm2d-384            [-1, 256, 3, 3]             512\n            ReLU-385            [-1, 256, 3, 3]               0\n            Conv-386            [-1, 256, 3, 3]               0\n          Conv2d-387            [-1, 256, 3, 3]         590,080\n     BatchNorm2d-388            [-1, 256, 3, 3]             512\n            ReLU-389            [-1, 256, 3, 3]               0\n            Conv-390            [-1, 256, 3, 3]               0\n       ConvStack-391            [-1, 256, 3, 3]               0\n          Conv2d-392            [-1, 256, 3, 3]         590,080\n     BatchNorm2d-393            [-1, 256, 3, 3]             512\n            ReLU-394            [-1, 256, 3, 3]               0\n            Conv-395            [-1, 256, 3, 3]               0\n          Conv2d-396            [-1, 256, 3, 3]         590,080\n     BatchNorm2d-397            [-1, 256, 3, 3]             512\n            ReLU-398            [-1, 256, 3, 3]               0\n            Conv-399            [-1, 256, 3, 3]               0\n          Conv2d-400            [-1, 256, 3, 3]         590,080\n     BatchNorm2d-401            [-1, 256, 3, 3]             512\n            ReLU-402            [-1, 256, 3, 3]               0\n            Conv-403            [-1, 256, 3, 3]               0\n          Conv2d-404            [-1, 256, 3, 3]         590,080\n     BatchNorm2d-405            [-1, 256, 3, 3]             512\n            ReLU-406            [-1, 256, 3, 3]               0\n            Conv-407            [-1, 256, 3, 3]               0\n       ConvStack-408            [-1, 256, 3, 3]               0\n          Conv2d-409            [-1, 256, 3, 3]         590,080\n     BatchNorm2d-410            [-1, 256, 3, 3]             512\n            ReLU-411            [-1, 256, 3, 3]               0\n            Conv-412            [-1, 256, 3, 3]               0\n          Conv2d-413            [-1, 256, 3, 3]         590,080\n     BatchNorm2d-414            [-1, 256, 3, 3]             512\n            ReLU-415            [-1, 256, 3, 3]               0\n            Conv-416            [-1, 256, 3, 3]               0\n          Conv2d-417            [-1, 256, 3, 3]         590,080\n     BatchNorm2d-418            [-1, 256, 3, 3]             512\n            ReLU-419            [-1, 256, 3, 3]               0\n            Conv-420            [-1, 256, 3, 3]               0\n          Conv2d-421            [-1, 256, 3, 3]         590,080\n     BatchNorm2d-422            [-1, 256, 3, 3]             512\n            ReLU-423            [-1, 256, 3, 3]               0\n            Conv-424            [-1, 256, 3, 3]               0\n       ConvStack-425            [-1, 256, 3, 3]               0\n          Conv2d-426            [-1, 256, 3, 3]         590,080\n     BatchNorm2d-427            [-1, 256, 3, 3]             512\n            ReLU-428            [-1, 256, 3, 3]               0\n            Conv-429            [-1, 256, 3, 3]               0\n          Conv2d-430            [-1, 256, 3, 3]         590,080\n     BatchNorm2d-431            [-1, 256, 3, 3]             512\n            ReLU-432            [-1, 256, 3, 3]               0\n            Conv-433            [-1, 256, 3, 3]               0\n          Conv2d-434            [-1, 256, 3, 3]         590,080\n     BatchNorm2d-435            [-1, 256, 3, 3]             512\n            ReLU-436            [-1, 256, 3, 3]               0\n            Conv-437            [-1, 256, 3, 3]               0\n          Conv2d-438            [-1, 256, 3, 3]         590,080\n     BatchNorm2d-439            [-1, 256, 3, 3]             512\n            ReLU-440            [-1, 256, 3, 3]               0\n            Conv-441            [-1, 256, 3, 3]               0\n       ConvStack-442            [-1, 256, 3, 3]               0\n     ResnetLayer-443            [-1, 256, 3, 3]               0\n          Conv2d-444            [-1, 512, 3, 3]       1,180,160\n       AvgPool2d-445            [-1, 512, 1, 1]               0\n     BatchNorm2d-446            [-1, 512, 1, 1]           1,024\n            ReLU-447            [-1, 512, 1, 1]               0\n         Pooling-448            [-1, 512, 1, 1]               0\n         Flatten-449                  [-1, 512]               0\n          Linear-450                 [-1, 4096]       2,101,248\n            ReLU-451                 [-1, 4096]               0\n          Linear-452                 [-1, 4096]      16,781,312\n            ReLU-453                 [-1, 4096]               0\n          Linear-454                    [-1, 2]           8,194\n         Softmax-455                    [-1, 2]               0\n  FullyConnected-456                    [-1, 2]               0\n================================================================\nTotal params: 33,070,530\nTrainable params: 33,070,530\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.11\nForward/backward pass size (MB): 83.20\nParams size (MB): 126.15\nEstimated Total Size (MB): 209.46\n----------------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Training the model","metadata":{}},{"cell_type":"code","source":"class Trainer:\n    def __init__(self,model,device,train_dataloader,valid_dataloader = None):\n        self.__model = model.to(device)\n        self.__device = device\n        self.__train_dataloader = self.__get_train_batch(train_dataloader)\n        self.__valid_dataloader = self.__get_train_batch(valid_dataloader) if valid_dataloader is not None else None\n    \n    @torch.no_grad()\n    def __get_train_batch(self,dataloader):\n        while True:\n            for images,labels in dataloader:\n                yield images.to(self.__device),labels.to(self.__device)\n    \n    @torch.no_grad()\n    def __compute_accuracy(self,probs,labels):\n        preds = torch.argmax(probs,dim = -1)\n        acc = torch.sum(preds == labels) / len(labels)\n        return acc * 100\n    \n    @torch.no_grad()\n    def __valid_step(self,valid_steps_per_epoch):\n        losses,accuracy = [],[]\n        for step in range(valid_steps_per_epoch):\n            images,labels = next(self.__valid_dataloader)\n            probs = self.__model(images)\n            one_hot = F.one_hot(labels,int(probs.shape[-1])).float()\n            loss = F.cross_entropy(probs,one_hot)\n            loss = round(loss.item(),3)\n            losses.append(loss)\n            accuracy.append(float(self.__compute_accuracy(probs,labels)))\n        return round(sum(losses) / len(losses),4),round(sum(accuracy) / len(accuracy),4)\n    \n    def __train_step(self,optimizer):\n        images,labels = next(self.__train_dataloader)\n        probs = self.__model(images)\n        one_hot = F.one_hot(labels,int(probs.shape[-1])).float()\n        loss = F.cross_entropy(probs,one_hot)\n        optimizer.zero_grad(set_to_none = True)\n        loss.backward()\n        optimizer.step()\n        loss = round(loss.item(),3)\n        return loss,self.__compute_accuracy(probs,labels)\n        \n    \n    def train(self,epochs,steps_per_epoch,valid_steps_per_epoch,optimizer = None,lr = 3e-4):\n        master_progress_bar = master_bar(range(epochs))\n        if optimizer is None:\n            optimizer = torch.optim.Adam(self.__model.parameters(),lr = lr)\n        lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer = optimizer,mode = \"min\",factor = 1 / 3,patience = 3)\n        \n        for epoch in master_progress_bar:\n            train_losses,train_accu = [],[]\n            for step in progress_bar(range(steps_per_epoch),parent = master_progress_bar):\n                train_loss,train_acc = self.__train_step(optimizer)\n                train_losses.append(train_loss)\n                train_accu.append(float(train_acc))\n                master_progress_bar.child.comment = f\"Loss: {train_loss}, Acc: {train_acc}\"\n            \n            train_loss = round(sum(train_losses) / len(train_losses),4)\n            train_acc = round(sum(train_accu) / len(train_accu),4)\n                \n            if self.__valid_dataloader is not None:\n                valid_loss,valid_acc = self.__valid_step(valid_steps_per_epoch)\n                master_progress_bar.write(f\"Train loss: {train_loss} - train acc: {train_acc} - valid loss: {valid_loss} - valid acc: {valid_acc}\")\n                \n            lr_scheduler.step(valid_loss)","metadata":{"execution":{"iopub.status.busy":"2024-04-03T09:54:20.221385Z","iopub.execute_input":"2024-04-03T09:54:20.221765Z","iopub.status.idle":"2024-04-03T09:54:20.239158Z","shell.execute_reply.started":"2024-04-03T09:54:20.22173Z","shell.execute_reply":"2024-04-03T09:54:20.238247Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(model = model,device = device,train_dataloader = train_dataloader,valid_dataloader = valid_dataloader)","metadata":{"execution":{"iopub.status.busy":"2024-04-03T09:54:20.240173Z","iopub.execute_input":"2024-04-03T09:54:20.240478Z","iopub.status.idle":"2024-04-03T09:54:20.258656Z","shell.execute_reply.started":"2024-04-03T09:54:20.240447Z","shell.execute_reply":"2024-04-03T09:54:20.257944Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"trainer.train(epochs = epochs,steps_per_epoch = 1125,valid_steps_per_epoch = 200)","metadata":{"execution":{"iopub.status.busy":"2024-04-03T09:54:20.259657Z","iopub.execute_input":"2024-04-03T09:54:20.259918Z","iopub.status.idle":"2024-04-03T11:00:55.21684Z","shell.execute_reply.started":"2024-04-03T09:54:20.259896Z","shell.execute_reply":"2024-04-03T11:00:55.216083Z"},"trusted":true},"execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Train loss: 0.5551 - train acc: 74.4611 - valid loss: 0.5401 - valid acc: 75.9375<p>Train loss: 0.5388 - train acc: 76.1667 - valid loss: 0.53 - valid acc: 77.5938<p>Train loss: 0.5292 - train acc: 77.125 - valid loss: 0.5252 - valid acc: 77.2031<p>Train loss: 0.522 - train acc: 77.8861 - valid loss: 0.5211 - valid acc: 77.2969<p>Train loss: 0.5306 - train acc: 77.1444 - valid loss: 0.5531 - valid acc: 74.7188<p>Train loss: 0.5323 - train acc: 76.8889 - valid loss: 0.5101 - valid acc: 79.3906<p>Train loss: 0.515 - train acc: 78.85 - valid loss: 0.5112 - valid acc: 79.1094<p>Train loss: 0.5112 - train acc: 79.1528 - valid loss: 0.5016 - valid acc: 79.7656<p>Train loss: 0.5108 - train acc: 79.1306 - valid loss: 0.5132 - valid acc: 78.4219<p>Train loss: 0.5104 - train acc: 79.2556 - valid loss: 0.5093 - valid acc: 79.2969<p>Train loss: 0.506 - train acc: 79.4861 - valid loss: 0.5165 - valid acc: 78.6719<p>Train loss: 0.5063 - train acc: 79.7306 - valid loss: 0.4997 - valid acc: 80.1875<p>Train loss: 0.5007 - train acc: 80.3 - valid loss: 0.5054 - valid acc: 80.0469<p>Train loss: 0.5197 - train acc: 78.3639 - valid loss: 0.5043 - valid acc: 79.9688<p>Train loss: 0.5107 - train acc: 79.1417 - valid loss: 0.5194 - valid acc: 77.75<p>Train loss: 0.5097 - train acc: 79.1167 - valid loss: 0.5019 - valid acc: 80.5156<p>Train loss: 0.4997 - train acc: 80.3306 - valid loss: 0.5075 - valid acc: 79.2344<p>Train loss: 0.4983 - train acc: 80.3778 - valid loss: 0.4981 - valid acc: 80.6406<p>Train loss: 0.4985 - train acc: 80.3 - valid loss: 0.4926 - valid acc: 81.0625<p>Train loss: 0.4912 - train acc: 81.2667 - valid loss: 0.4882 - valid acc: 81.5156<p>Train loss: 0.4943 - train acc: 80.8611 - valid loss: 0.4894 - valid acc: 81.4219<p>Train loss: 0.4914 - train acc: 81.0139 - valid loss: 0.4865 - valid acc: 81.5312<p>Train loss: 0.4901 - train acc: 81.2556 - valid loss: 0.4912 - valid acc: 81.1094<p>Train loss: 0.4873 - train acc: 81.65 - valid loss: 0.4896 - valid acc: 81.5469<p>Train loss: 0.4871 - train acc: 81.6444 - valid loss: 0.4849 - valid acc: 81.7344<p>Train loss: 0.4851 - train acc: 81.7778 - valid loss: 0.4807 - valid acc: 82.1719<p>Train loss: 0.4871 - train acc: 81.7694 - valid loss: 0.4876 - valid acc: 81.6094<p>Train loss: 0.4842 - train acc: 81.8833 - valid loss: 0.4899 - valid acc: 81.0781<p>Train loss: 0.4832 - train acc: 82.0694 - valid loss: 0.4809 - valid acc: 82.3125<p>Train loss: 0.484 - train acc: 81.8833 - valid loss: 0.4931 - valid acc: 80.9844"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}