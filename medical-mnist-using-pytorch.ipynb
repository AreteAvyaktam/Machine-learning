{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1099232,"sourceType":"datasetVersion","datasetId":614679}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch-summary","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-21T18:06:55.072547Z","iopub.execute_input":"2024-05-21T18:06:55.072907Z","iopub.status.idle":"2024-05-21T18:07:08.987353Z","shell.execute_reply.started":"2024-05-21T18:06:55.072879Z","shell.execute_reply":"2024-05-21T18:07:08.986424Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting torch-summary\n  Downloading torch_summary-1.4.5-py3-none-any.whl.metadata (18 kB)\nDownloading torch_summary-1.4.5-py3-none-any.whl (16 kB)\nInstalling collected packages: torch-summary\nSuccessfully installed torch-summary-1.4.5\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport os\nimport shutil\nimport random\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.transforms as transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\nfrom fastprogress import master_bar,progress_bar\nfrom tqdm import tqdm\nfrom torchsummary import summary","metadata":{"execution":{"iopub.status.busy":"2024-05-21T18:07:11.133668Z","iopub.execute_input":"2024-05-21T18:07:11.134076Z","iopub.status.idle":"2024-05-21T18:07:19.671530Z","shell.execute_reply.started":"2024-05-21T18:07:11.134043Z","shell.execute_reply":"2024-05-21T18:07:19.670571Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Building the model","metadata":{}},{"cell_type":"code","source":"class Conv2d(nn.Module):\n    def __init__(self,in_channels,out_channels,kernel_size = 3):\n        super().__init__()\n        self.model = nn.Sequential(*[\n            nn.Conv2d(in_channels,out_channels,kernel_size = kernel_size,stride = 1,padding = (kernel_size - 1) // 2),\n            nn.BatchNorm2d(num_features = out_channels),\n            nn.ReLU()\n        ])\n    \n    def forward(self,x):\n        return self.model(x)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T18:07:26.243751Z","iopub.execute_input":"2024-05-21T18:07:26.244915Z","iopub.status.idle":"2024-05-21T18:07:26.250715Z","shell.execute_reply.started":"2024-05-21T18:07:26.244882Z","shell.execute_reply":"2024-05-21T18:07:26.249832Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class Dense(nn.Module):\n    def __init__(self,in_features,out_features,activation = nn.ReLU()):\n        super().__init__()\n        self.model = nn.Sequential(*[\n            nn.Linear(in_features,out_features),\n            activation\n        ])\n    \n    def forward(self,x):\n        return self.model(x)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T18:07:26.552434Z","iopub.execute_input":"2024-05-21T18:07:26.553253Z","iopub.status.idle":"2024-05-21T18:07:26.558637Z","shell.execute_reply.started":"2024-05-21T18:07:26.553223Z","shell.execute_reply":"2024-05-21T18:07:26.557710Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class ConvStack(nn.Module):\n    def __init__(self,in_channels,num_conv = 3):\n        super().__init__()\n        self.model = nn.Sequential(*[\n            Conv2d(in_channels,in_channels // 2,kernel_size = 1),\n            *[Conv2d(in_channels // 2,in_channels // 2) for _ in range(num_conv - 1)],\n            Conv2d(in_channels // 2,2 * in_channels),\n            nn.Dropout(0.25)\n        ])\n        self.out_channels = in_channels * 2\n    \n    def forward(self,x):\n        return self.model(x)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T18:07:26.901299Z","iopub.execute_input":"2024-05-21T18:07:26.901894Z","iopub.status.idle":"2024-05-21T18:07:26.908040Z","shell.execute_reply.started":"2024-05-21T18:07:26.901866Z","shell.execute_reply":"2024-05-21T18:07:26.907140Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class Pool(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.model = nn.Sequential(*[\n            nn.AvgPool2d(kernel_size = 2,stride = 2),\n            nn.ReLU(),\n        ])\n    \n    def forward(self,x):\n        return self.model(x)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T18:07:27.250336Z","iopub.execute_input":"2024-05-21T18:07:27.250912Z","iopub.status.idle":"2024-05-21T18:07:27.256498Z","shell.execute_reply.started":"2024-05-21T18:07:27.250883Z","shell.execute_reply":"2024-05-21T18:07:27.255488Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class FCN(nn.Module):\n    def __init__(self,out_channels,num_classes,units = 4096):\n        super().__init__()\n        self.model = nn.Sequential(*[\n            nn.Flatten(),\n            Dense(out_channels,units),\n            Dense(units,units),\n            Dense(units,units),\n            Dense(units,num_classes,activation = nn.Softmax())\n        ])\n    \n    def forward(self,x):\n        return self.model(x)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T18:07:27.688478Z","iopub.execute_input":"2024-05-21T18:07:27.688941Z","iopub.status.idle":"2024-05-21T18:07:27.695339Z","shell.execute_reply.started":"2024-05-21T18:07:27.688910Z","shell.execute_reply":"2024-05-21T18:07:27.694342Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class Resnet(nn.Module):\n    def __init__(self,image_size,num_classes,units = 4096,num_conv = 5):\n        super().__init__()\n        height,width = image_size\n        channels = 3\n        self.model = []\n        while height > 1:\n            self.model.extend([\n                ConvStack(channels,num_conv),\n                Pool()\n            ])\n            channels = self.model[-2].out_channels\n            height //= 2\n        self.model.append(FCN(channels,num_classes,units))\n        self.model = nn.Sequential(*self.model)\n    \n    def forward(self,x):\n        return self.model(x)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T18:07:28.075953Z","iopub.execute_input":"2024-05-21T18:07:28.076318Z","iopub.status.idle":"2024-05-21T18:07:28.083361Z","shell.execute_reply.started":"2024-05-21T18:07:28.076291Z","shell.execute_reply":"2024-05-21T18:07:28.082418Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Handling the data","metadata":{}},{"cell_type":"code","source":"image_data_path = \"/kaggle/input/medical-mnist\"","metadata":{"execution":{"iopub.status.busy":"2024-05-21T18:07:28.887975Z","iopub.execute_input":"2024-05-21T18:07:28.888684Z","iopub.status.idle":"2024-05-21T18:07:28.892737Z","shell.execute_reply.started":"2024-05-21T18:07:28.888655Z","shell.execute_reply":"2024-05-21T18:07:28.891677Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"classes = os.listdir(image_data_path)\nprint(classes)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T18:07:29.245458Z","iopub.execute_input":"2024-05-21T18:07:29.245967Z","iopub.status.idle":"2024-05-21T18:07:29.270153Z","shell.execute_reply.started":"2024-05-21T18:07:29.245935Z","shell.execute_reply":"2024-05-21T18:07:29.269241Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"['AbdomenCT', 'BreastMRI', 'Hand', 'CXR', 'HeadCT', 'ChestCT']\n","output_type":"stream"}]},{"cell_type":"code","source":"model_data_parent_dir = \"/kaggle/data\"\ntrain_path = os.path.join(model_data_parent_dir,\"train\")\nvalid_path = os.path.join(model_data_parent_dir,\"valid\")\ntest_path = os.path.join(model_data_parent_dir,\"test\")","metadata":{"execution":{"iopub.status.busy":"2024-05-21T18:07:29.601309Z","iopub.execute_input":"2024-05-21T18:07:29.601665Z","iopub.status.idle":"2024-05-21T18:07:29.606541Z","shell.execute_reply.started":"2024-05-21T18:07:29.601637Z","shell.execute_reply":"2024-05-21T18:07:29.605641Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def create_paths(parent_dir,classes):\n    types = ['train','valid','test']\n    if os.path.exists(parent_dir) is False:\n        os.mkdir(parent_dir)\n        \n        for t in types:\n            type_path = os.path.join(parent_dir,t)\n            os.mkdir(type_path)\n            print(f\"{type_path} has been constructed\")\n            for target in classes:\n                target_path = os.path.join(type_path,target)\n                os.mkdir(target_path)\n                print(f\"{target_path} has been constructed\")","metadata":{"execution":{"iopub.status.busy":"2024-05-21T18:07:29.985430Z","iopub.execute_input":"2024-05-21T18:07:29.985792Z","iopub.status.idle":"2024-05-21T18:07:29.991923Z","shell.execute_reply.started":"2024-05-21T18:07:29.985765Z","shell.execute_reply":"2024-05-21T18:07:29.991018Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"create_paths(model_data_parent_dir,classes)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T18:07:30.513143Z","iopub.execute_input":"2024-05-21T18:07:30.513789Z","iopub.status.idle":"2024-05-21T18:07:30.521146Z","shell.execute_reply.started":"2024-05-21T18:07:30.513758Z","shell.execute_reply":"2024-05-21T18:07:30.520226Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"/kaggle/data/train has been constructed\n/kaggle/data/train/AbdomenCT has been constructed\n/kaggle/data/train/BreastMRI has been constructed\n/kaggle/data/train/Hand has been constructed\n/kaggle/data/train/CXR has been constructed\n/kaggle/data/train/HeadCT has been constructed\n/kaggle/data/train/ChestCT has been constructed\n/kaggle/data/valid has been constructed\n/kaggle/data/valid/AbdomenCT has been constructed\n/kaggle/data/valid/BreastMRI has been constructed\n/kaggle/data/valid/Hand has been constructed\n/kaggle/data/valid/CXR has been constructed\n/kaggle/data/valid/HeadCT has been constructed\n/kaggle/data/valid/ChestCT has been constructed\n/kaggle/data/test has been constructed\n/kaggle/data/test/AbdomenCT has been constructed\n/kaggle/data/test/BreastMRI has been constructed\n/kaggle/data/test/Hand has been constructed\n/kaggle/data/test/CXR has been constructed\n/kaggle/data/test/HeadCT has been constructed\n/kaggle/data/test/ChestCT has been constructed\n","output_type":"stream"}]},{"cell_type":"code","source":"def move_data(src_dir,tgt_dir,mode,size):\n    for target in os.listdir(src_dir):\n        target_dir = os.path.join(src_dir,target)\n        target_files = random.sample(os.listdir(target_dir),size)\n        dest_dir = os.path.join(tgt_dir,target)\n        print(f\"Moving {mode} images for class: {target}\")\n        \n        for target_file in tqdm(target_files):\n            target_file_path = os.path.join(target_dir,target_file)\n            shutil.copy(target_file_path,dest_dir)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T18:07:31.153467Z","iopub.execute_input":"2024-05-21T18:07:31.154223Z","iopub.status.idle":"2024-05-21T18:07:31.159945Z","shell.execute_reply.started":"2024-05-21T18:07:31.154193Z","shell.execute_reply":"2024-05-21T18:07:31.159030Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"move_data(image_data_path,train_path,\"train\",6000)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T18:07:31.710167Z","iopub.execute_input":"2024-05-21T18:07:31.711031Z","iopub.status.idle":"2024-05-21T18:14:28.157456Z","shell.execute_reply.started":"2024-05-21T18:07:31.710993Z","shell.execute_reply":"2024-05-21T18:14:28.156533Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Moving train images for class: AbdomenCT\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6000/6000 [01:09<00:00, 85.87it/s] \n","output_type":"stream"},{"name":"stdout","text":"Moving train images for class: BreastMRI\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6000/6000 [01:07<00:00, 88.78it/s] \n","output_type":"stream"},{"name":"stdout","text":"Moving train images for class: Hand\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6000/6000 [01:07<00:00, 88.45it/s] \n","output_type":"stream"},{"name":"stdout","text":"Moving train images for class: CXR\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6000/6000 [01:06<00:00, 90.02it/s] \n","output_type":"stream"},{"name":"stdout","text":"Moving train images for class: HeadCT\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6000/6000 [01:06<00:00, 89.76it/s] \n","output_type":"stream"},{"name":"stdout","text":"Moving train images for class: ChestCT\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6000/6000 [01:10<00:00, 85.53it/s] \n","output_type":"stream"}]},{"cell_type":"code","source":"move_data(image_data_path,valid_path,\"valid\",2000)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T18:14:31.776344Z","iopub.execute_input":"2024-05-21T18:14:31.777294Z","iopub.status.idle":"2024-05-21T18:15:31.012391Z","shell.execute_reply.started":"2024-05-21T18:14:31.777247Z","shell.execute_reply":"2024-05-21T18:15:31.011312Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Moving valid images for class: AbdomenCT\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2000/2000 [00:09<00:00, 204.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Moving valid images for class: BreastMRI\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2000/2000 [00:08<00:00, 235.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Moving valid images for class: Hand\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2000/2000 [00:10<00:00, 190.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"Moving valid images for class: CXR\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2000/2000 [00:10<00:00, 194.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Moving valid images for class: HeadCT\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2000/2000 [00:10<00:00, 197.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Moving valid images for class: ChestCT\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2000/2000 [00:10<00:00, 199.84it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"image_size = (96,96)\nbatch_size = 32\nepochs = 10\nsteps_per_epoch = 1125\nvalid_epochs = 15\nvalid_steps_per_epoch = 200\ndevice = \"cuda\" if torch.cuda.is_available() is True else \"cpu\"\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T19:05:44.109205Z","iopub.execute_input":"2024-05-21T19:05:44.109576Z","iopub.status.idle":"2024-05-21T19:05:44.115817Z","shell.execute_reply.started":"2024-05-21T19:05:44.109546Z","shell.execute_reply":"2024-05-21T19:05:44.114900Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Resize(size = image_size,antialias = True),\n    transforms.Normalize(mean = [0.5],std = [0.5]),\n    transforms.RandomHorizontalFlip()\n])\n\nvalid_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean = [0.5],std = [0.5]),\n    transforms.Resize(size = image_size,antialias = True),\n])","metadata":{"execution":{"iopub.status.busy":"2024-05-21T18:15:33.267268Z","iopub.execute_input":"2024-05-21T18:15:33.268129Z","iopub.status.idle":"2024-05-21T18:15:33.275290Z","shell.execute_reply.started":"2024-05-21T18:15:33.268089Z","shell.execute_reply":"2024-05-21T18:15:33.274360Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"train_dataset = ImageFolder(root = train_path,transform = train_transform)\nvalid_dataset = ImageFolder(root = valid_path,transform = valid_transform)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T18:15:34.118427Z","iopub.execute_input":"2024-05-21T18:15:34.118837Z","iopub.status.idle":"2024-05-21T18:15:34.336725Z","shell.execute_reply.started":"2024-05-21T18:15:34.118808Z","shell.execute_reply":"2024-05-21T18:15:34.335691Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"train_dataloader = DataLoader(dataset = train_dataset,batch_size = batch_size,shuffle = True,\n                             drop_last = True)\n\nvalid_dataloader = DataLoader(dataset = valid_dataset,batch_size = batch_size,drop_last = True)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T18:56:46.901938Z","iopub.execute_input":"2024-05-21T18:56:46.902664Z","iopub.status.idle":"2024-05-21T18:56:46.907464Z","shell.execute_reply.started":"2024-05-21T18:56:46.902630Z","shell.execute_reply":"2024-05-21T18:56:46.906598Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"# Trainer","metadata":{}},{"cell_type":"code","source":"class Trainer:\n    def __init__(self,model,device,train_dataloader,valid_dataloader):\n        self.model = model.to(device)\n        self.device = device\n        self.train_dataloader = train_dataloader\n        self.valid_dataloader = valid_dataloader\n    \n    def train(self,epochs,loss_fn = None,optimizer = None):\n        loss_fn = nn.CrossEntropyLoss() if loss_fn is None else loss_fn\n        optimizer = torch.optim.Adam(self.model.parameters(),lr = 4.236429595039226e-05) if optimizer is None else optimizer\n        \n        parent_bar = master_bar(range(epochs))\n        for epoch in parent_bar:\n            train_batch_losses,train_batch_acc = [],[]\n            train_samples = 0\n            child_bar = progress_bar(self.train_dataloader,parent = parent_bar)\n            self.model.train()\n            \n            for train_images,train_labels in child_bar:\n                train_images,train_labels = train_images.to(self.device),train_labels.to(self.device)\n                optimizer.zero_grad(set_to_none = True)\n                probs = self.model(train_images)\n                loss = loss_fn(probs,train_labels)\n                train_batch_losses.append(round(loss.data.item() * train_images.shape[0],3))\n                _,labels = torch.max(probs,dim = 1)\n                train_samples += train_images.shape[0]\n                match_tensor = (labels == train_labels).float()\n                train_batch_acc.append(round(float(match_tensor.sum().item()),3))\n                loss.backward()\n                optimizer.step()\n                parent_bar.child.comment = f\"Train loss: {train_batch_losses[-1] / train_images.shape[0]}, train acc: {train_batch_acc[-1] / train_labels.shape[0]}\"\n            \n            train_batch_losses = round(sum(train_batch_losses) / train_samples,3)\n            train_batch_acc = round(sum(train_batch_acc) / train_samples,3)\n            \n            valid_batch_losses,valid_batch_acc = [],[]\n            valid_samples = 0\n            child_bar = progress_bar(self.valid_dataloader,parent = parent_bar)\n            self.model.eval()\n            \n            with torch.no_grad():\n                for valid_images,valid_labels in child_bar:\n                    valid_images,valid_labels = valid_images.to(self.device),valid_labels.to(self.device)\n                    probs = self.model(valid_images)\n                    loss = loss_fn(probs,valid_labels)\n                    valid_batch_losses.append(round(loss.item() * valid_images.shape[0],3))\n                    _,labels = torch.max(probs,dim = 1)\n                    valid_samples += valid_images.shape[0]\n                    match_tensor = (labels == valid_labels).float()\n                    valid_batch_acc.append(round(float(match_tensor.sum().item()),3))\n                    parent_bar.child.comment = f\"Valid loss: {valid_batch_losses[-1] / valid_images.shape[0]}, valid acc: {valid_batch_acc[-1] / valid_images.shape[0]}\"\n            \n            valid_batch_losses = round(sum(valid_batch_losses) / valid_samples,3)\n            valid_batch_acc = round(sum(valid_batch_acc) / valid_samples,3)\n            \n            parent_bar.write(f\"Epoch: {epoch + 1} / {epochs} -> Train loss: {train_batch_losses}, train acc: {train_batch_acc}, valid loss: {valid_batch_losses}, valid acc: {valid_batch_acc}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-21T19:05:47.390134Z","iopub.execute_input":"2024-05-21T19:05:47.390496Z","iopub.status.idle":"2024-05-21T19:05:47.406479Z","shell.execute_reply.started":"2024-05-21T19:05:47.390468Z","shell.execute_reply":"2024-05-21T19:05:47.405520Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"model = Resnet(image_size = image_size,num_classes = len(classes),num_conv = 3)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T19:05:47.591441Z","iopub.execute_input":"2024-05-21T19:05:47.591762Z","iopub.status.idle":"2024-05-21T19:05:47.940764Z","shell.execute_reply.started":"2024-05-21T19:05:47.591735Z","shell.execute_reply":"2024-05-21T19:05:47.939947Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(model,device,train_dataloader,valid_dataloader)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T19:05:47.942339Z","iopub.execute_input":"2024-05-21T19:05:47.942633Z","iopub.status.idle":"2024-05-21T19:05:47.991361Z","shell.execute_reply.started":"2024-05-21T19:05:47.942607Z","shell.execute_reply":"2024-05-21T19:05:47.990681Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"trainer.train(epochs = epochs)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T19:05:48.189447Z","iopub.execute_input":"2024-05-21T19:05:48.189747Z","iopub.status.idle":"2024-05-21T19:15:15.574114Z","shell.execute_reply.started":"2024-05-21T19:05:48.189715Z","shell.execute_reply":"2024-05-21T19:15:15.573041Z"},"trusted":true},"execution_count":45,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Epoch: 1 / 10 -> Train loss: 1.288, train acc: 0.752, valid loss: 1.18, valid acc: 0.863<p>Epoch: 2 / 10 -> Train loss: 1.142, train acc: 0.901, valid loss: 1.14, valid acc: 0.903<p>Epoch: 3 / 10 -> Train loss: 1.123, train acc: 0.921, valid loss: 1.092, valid acc: 0.951<p>Epoch: 4 / 10 -> Train loss: 1.109, train acc: 0.934, valid loss: 1.061, valid acc: 0.983<p>Epoch: 5 / 10 -> Train loss: 1.099, train acc: 0.944, valid loss: 1.102, valid acc: 0.941<p>Epoch: 6 / 10 -> Train loss: 1.092, train acc: 0.952, valid loss: 1.148, valid acc: 0.895<p>Epoch: 7 / 10 -> Train loss: 1.085, train acc: 0.958, valid loss: 1.068, valid acc: 0.976<p>Epoch: 8 / 10 -> Train loss: 1.082, train acc: 0.961, valid loss: 1.059, valid acc: 0.985<p>Epoch: 9 / 10 -> Train loss: 1.076, train acc: 0.968, valid loss: 1.057, valid acc: 0.987<p>Epoch: 10 / 10 -> Train loss: 1.073, train acc: 0.97, valid loss: 1.073, valid acc: 0.97"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}