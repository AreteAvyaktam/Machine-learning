{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1099232,"sourceType":"datasetVersion","datasetId":614679}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch-summary","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-26T17:38:26.155868Z","iopub.execute_input":"2024-05-26T17:38:26.156362Z","iopub.status.idle":"2024-05-26T17:38:41.083377Z","shell.execute_reply.started":"2024-05-26T17:38:26.156320Z","shell.execute_reply":"2024-05-26T17:38:41.082273Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting torch-summary\n  Downloading torch_summary-1.4.5-py3-none-any.whl.metadata (18 kB)\nDownloading torch_summary-1.4.5-py3-none-any.whl (16 kB)\nInstalling collected packages: torch-summary\nSuccessfully installed torch-summary-1.4.5\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport os\nimport shutil\nimport random\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.transforms as transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\nfrom fastprogress import master_bar,progress_bar\nfrom tqdm import tqdm\nfrom torchsummary import summary","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:38:41.086195Z","iopub.execute_input":"2024-05-26T17:38:41.087189Z","iopub.status.idle":"2024-05-26T17:38:47.381854Z","shell.execute_reply.started":"2024-05-26T17:38:41.087143Z","shell.execute_reply":"2024-05-26T17:38:47.380948Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Building the model","metadata":{}},{"cell_type":"code","source":"class Conv2d(nn.Module):\n    def __init__(self,in_channels,out_channels,kernel_size = 3):\n        super().__init__()\n        self.model = nn.Sequential(*[\n            nn.Conv2d(in_channels,out_channels,kernel_size = kernel_size,stride = 1,padding = (kernel_size - 1) // 2),\n            nn.BatchNorm2d(num_features = out_channels),\n            nn.ReLU()\n        ])\n    \n    def forward(self,x):\n        return self.model(x)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:38:47.383146Z","iopub.execute_input":"2024-05-26T17:38:47.383695Z","iopub.status.idle":"2024-05-26T17:38:47.391071Z","shell.execute_reply.started":"2024-05-26T17:38:47.383659Z","shell.execute_reply":"2024-05-26T17:38:47.389735Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class Dense(nn.Module):\n    def __init__(self,in_features,out_features,activation = nn.ReLU()):\n        super().__init__()\n        self.model = nn.Sequential(*[\n            nn.Linear(in_features,out_features),\n            activation\n        ])\n    \n    def forward(self,x):\n        return self.model(x)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:38:47.392862Z","iopub.execute_input":"2024-05-26T17:38:47.393234Z","iopub.status.idle":"2024-05-26T17:38:47.403331Z","shell.execute_reply.started":"2024-05-26T17:38:47.393191Z","shell.execute_reply":"2024-05-26T17:38:47.402350Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class ConvStack(nn.Module):\n    def __init__(self,in_channels,num_conv = 3):\n        super().__init__()\n        self.model = nn.Sequential(*[\n            Conv2d(in_channels,in_channels // 2,kernel_size = 1),\n            *[Conv2d(in_channels // 2,in_channels // 2) for _ in range(num_conv - 1)],\n            Conv2d(in_channels // 2,2 * in_channels),\n            nn.Dropout(0.25)\n        ])\n        self.out_channels = in_channels * 2\n        self.add_helper = Conv2d(in_channels,self.out_channels,kernel_size = 1)\n    \n    def forward(self,x):\n        return F.relu(self.model(x) + self.add_helper(x))","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:46:54.927931Z","iopub.execute_input":"2024-05-26T17:46:54.928751Z","iopub.status.idle":"2024-05-26T17:46:54.936476Z","shell.execute_reply.started":"2024-05-26T17:46:54.928716Z","shell.execute_reply":"2024-05-26T17:46:54.935389Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"class Pool(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.model = nn.Sequential(*[\n            nn.AvgPool2d(kernel_size = 2,stride = 2),\n            nn.ReLU(),\n        ])\n    \n    def forward(self,x):\n        return self.model(x)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:38:47.415904Z","iopub.execute_input":"2024-05-26T17:38:47.416244Z","iopub.status.idle":"2024-05-26T17:38:47.423965Z","shell.execute_reply.started":"2024-05-26T17:38:47.416217Z","shell.execute_reply":"2024-05-26T17:38:47.422969Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class FCN(nn.Module):\n    def __init__(self,out_channels,num_classes,units = 4096):\n        super().__init__()\n        self.model = nn.Sequential(*[\n            nn.Flatten(),\n            Dense(out_channels,units),\n            Dense(units,units),\n            Dense(units,units),\n            Dense(units,num_classes,activation = nn.Softmax())\n        ])\n    \n    def forward(self,x):\n        return self.model(x)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:38:47.425208Z","iopub.execute_input":"2024-05-26T17:38:47.425899Z","iopub.status.idle":"2024-05-26T17:38:47.434050Z","shell.execute_reply.started":"2024-05-26T17:38:47.425870Z","shell.execute_reply":"2024-05-26T17:38:47.433124Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class Resnet(nn.Module):\n    def __init__(self,image_size,num_classes,units = 4096,num_conv = 5):\n        super().__init__()\n        height,width = image_size\n        channels = 3\n        self.model = []\n        while height > 1:\n            self.model.extend([\n                ConvStack(channels,num_conv),\n                Pool()\n            ])\n            channels = self.model[-2].out_channels\n            height //= 2\n        self.model.append(FCN(channels,num_classes,units))\n        self.model = nn.Sequential(*self.model)\n    \n    def forward(self,x):\n        return self.model(x)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:38:47.435276Z","iopub.execute_input":"2024-05-26T17:38:47.435606Z","iopub.status.idle":"2024-05-26T17:38:47.447622Z","shell.execute_reply.started":"2024-05-26T17:38:47.435582Z","shell.execute_reply":"2024-05-26T17:38:47.446541Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Handling the data","metadata":{}},{"cell_type":"code","source":"image_data_path = \"/kaggle/input/medical-mnist\"","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:38:47.449004Z","iopub.execute_input":"2024-05-26T17:38:47.449445Z","iopub.status.idle":"2024-05-26T17:38:47.457159Z","shell.execute_reply.started":"2024-05-26T17:38:47.449408Z","shell.execute_reply":"2024-05-26T17:38:47.456187Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"classes = os.listdir(image_data_path)\nprint(classes)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:38:47.458443Z","iopub.execute_input":"2024-05-26T17:38:47.458771Z","iopub.status.idle":"2024-05-26T17:38:47.475402Z","shell.execute_reply.started":"2024-05-26T17:38:47.458744Z","shell.execute_reply":"2024-05-26T17:38:47.474312Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"['AbdomenCT', 'BreastMRI', 'Hand', 'CXR', 'HeadCT', 'ChestCT']\n","output_type":"stream"}]},{"cell_type":"code","source":"model_data_parent_dir = \"/kaggle/data\"\ntrain_path = os.path.join(model_data_parent_dir,\"train\")\nvalid_path = os.path.join(model_data_parent_dir,\"valid\")\ntest_path = os.path.join(model_data_parent_dir,\"test\")","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:38:47.476592Z","iopub.execute_input":"2024-05-26T17:38:47.476884Z","iopub.status.idle":"2024-05-26T17:38:47.482482Z","shell.execute_reply.started":"2024-05-26T17:38:47.476861Z","shell.execute_reply":"2024-05-26T17:38:47.481367Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def create_paths(parent_dir,classes):\n    types = ['train','valid','test']\n    if os.path.exists(parent_dir) is False:\n        os.mkdir(parent_dir)\n        \n        for t in types:\n            type_path = os.path.join(parent_dir,t)\n            os.mkdir(type_path)\n            print(f\"{type_path} has been constructed\")\n            for target in classes:\n                target_path = os.path.join(type_path,target)\n                os.mkdir(target_path)\n                print(f\"{target_path} has been constructed\")","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:38:47.484050Z","iopub.execute_input":"2024-05-26T17:38:47.484421Z","iopub.status.idle":"2024-05-26T17:38:47.492624Z","shell.execute_reply.started":"2024-05-26T17:38:47.484391Z","shell.execute_reply":"2024-05-26T17:38:47.491491Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"create_paths(model_data_parent_dir,classes)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:38:47.494054Z","iopub.execute_input":"2024-05-26T17:38:47.494445Z","iopub.status.idle":"2024-05-26T17:38:47.505980Z","shell.execute_reply.started":"2024-05-26T17:38:47.494413Z","shell.execute_reply":"2024-05-26T17:38:47.504876Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"/kaggle/data/train has been constructed\n/kaggle/data/train/AbdomenCT has been constructed\n/kaggle/data/train/BreastMRI has been constructed\n/kaggle/data/train/Hand has been constructed\n/kaggle/data/train/CXR has been constructed\n/kaggle/data/train/HeadCT has been constructed\n/kaggle/data/train/ChestCT has been constructed\n/kaggle/data/valid has been constructed\n/kaggle/data/valid/AbdomenCT has been constructed\n/kaggle/data/valid/BreastMRI has been constructed\n/kaggle/data/valid/Hand has been constructed\n/kaggle/data/valid/CXR has been constructed\n/kaggle/data/valid/HeadCT has been constructed\n/kaggle/data/valid/ChestCT has been constructed\n/kaggle/data/test has been constructed\n/kaggle/data/test/AbdomenCT has been constructed\n/kaggle/data/test/BreastMRI has been constructed\n/kaggle/data/test/Hand has been constructed\n/kaggle/data/test/CXR has been constructed\n/kaggle/data/test/HeadCT has been constructed\n/kaggle/data/test/ChestCT has been constructed\n","output_type":"stream"}]},{"cell_type":"code","source":"def move_data(src_dir,tgt_dir,mode,size):\n    for target in os.listdir(src_dir):\n        target_dir = os.path.join(src_dir,target)\n        target_files = random.sample(os.listdir(target_dir),size)\n        dest_dir = os.path.join(tgt_dir,target)\n        print(f\"Moving {mode} images for class: {target}\")\n        \n        for target_file in tqdm(target_files):\n            target_file_path = os.path.join(target_dir,target_file)\n            shutil.copy(target_file_path,dest_dir)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:38:47.510358Z","iopub.execute_input":"2024-05-26T17:38:47.511191Z","iopub.status.idle":"2024-05-26T17:38:47.518176Z","shell.execute_reply.started":"2024-05-26T17:38:47.511152Z","shell.execute_reply":"2024-05-26T17:38:47.517062Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"move_data(image_data_path,train_path,\"train\",6000)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:38:47.519322Z","iopub.execute_input":"2024-05-26T17:38:47.519662Z","iopub.status.idle":"2024-05-26T17:43:33.662868Z","shell.execute_reply.started":"2024-05-26T17:38:47.519636Z","shell.execute_reply":"2024-05-26T17:43:33.661883Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Moving train images for class: AbdomenCT\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6000/6000 [00:47<00:00, 125.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Moving train images for class: BreastMRI\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6000/6000 [00:47<00:00, 127.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Moving train images for class: Hand\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6000/6000 [00:46<00:00, 128.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Moving train images for class: CXR\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6000/6000 [00:46<00:00, 129.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Moving train images for class: HeadCT\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6000/6000 [00:46<00:00, 128.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Moving train images for class: ChestCT\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6000/6000 [00:47<00:00, 126.42it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"move_data(image_data_path,valid_path,\"valid\",2000)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:43:33.664247Z","iopub.execute_input":"2024-05-26T17:43:33.664592Z","iopub.status.idle":"2024-05-26T17:44:16.270561Z","shell.execute_reply.started":"2024-05-26T17:43:33.664565Z","shell.execute_reply":"2024-05-26T17:44:16.269543Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Moving valid images for class: AbdomenCT\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2000/2000 [00:07<00:00, 280.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Moving valid images for class: BreastMRI\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2000/2000 [00:06<00:00, 326.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Moving valid images for class: Hand\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2000/2000 [00:07<00:00, 278.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"Moving valid images for class: CXR\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2000/2000 [00:07<00:00, 264.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Moving valid images for class: HeadCT\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2000/2000 [00:07<00:00, 271.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Moving valid images for class: ChestCT\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2000/2000 [00:07<00:00, 277.96it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"image_size = (96,96)\nbatch_size = 32\nepochs = 10\nsteps_per_epoch = 1125\nvalid_epochs = 15\nvalid_steps_per_epoch = 200\ndevice = \"cuda\" if torch.cuda.is_available() is True else \"cpu\"\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:44:16.271747Z","iopub.execute_input":"2024-05-26T17:44:16.272019Z","iopub.status.idle":"2024-05-26T17:44:16.305742Z","shell.execute_reply.started":"2024-05-26T17:44:16.271996Z","shell.execute_reply":"2024-05-26T17:44:16.304538Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Resize(size = image_size,antialias = True),\n    transforms.Normalize(mean = [0.5],std = [0.5]),\n    transforms.RandomHorizontalFlip()\n])\n\nvalid_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean = [0.5],std = [0.5]),\n    transforms.Resize(size = image_size,antialias = True),\n])","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:44:16.307291Z","iopub.execute_input":"2024-05-26T17:44:16.307713Z","iopub.status.idle":"2024-05-26T17:44:16.332741Z","shell.execute_reply.started":"2024-05-26T17:44:16.307677Z","shell.execute_reply":"2024-05-26T17:44:16.331760Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"train_dataset = ImageFolder(root = train_path,transform = train_transform)\nvalid_dataset = ImageFolder(root = valid_path,transform = valid_transform)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:44:16.334038Z","iopub.execute_input":"2024-05-26T17:44:16.334775Z","iopub.status.idle":"2024-05-26T17:44:16.557322Z","shell.execute_reply.started":"2024-05-26T17:44:16.334737Z","shell.execute_reply":"2024-05-26T17:44:16.556499Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"train_dataloader = DataLoader(dataset = train_dataset,batch_size = batch_size,shuffle = True,\n                             drop_last = True)\n\nvalid_dataloader = DataLoader(dataset = valid_dataset,batch_size = batch_size,drop_last = True)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:44:16.558429Z","iopub.execute_input":"2024-05-26T17:44:16.558737Z","iopub.status.idle":"2024-05-26T17:44:16.564166Z","shell.execute_reply.started":"2024-05-26T17:44:16.558712Z","shell.execute_reply":"2024-05-26T17:44:16.563082Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# Trainer","metadata":{}},{"cell_type":"code","source":"class Trainer:\n    def __init__(self,model,device,train_dataloader,valid_dataloader):\n        self.model = model.to(device)\n        self.device = device\n        self.train_dataloader = train_dataloader\n        self.valid_dataloader = valid_dataloader\n    \n    def train(self,epochs,loss_fn = None,optimizer = None):\n        loss_fn = nn.CrossEntropyLoss() if loss_fn is None else loss_fn\n        optimizer = torch.optim.Adam(self.model.parameters(),lr = 4.236429595039226e-05) if optimizer is None else optimizer\n        \n        parent_bar = master_bar(range(epochs))\n        for epoch in parent_bar:\n            train_batch_losses,train_batch_acc = [],[]\n            train_samples = 0\n            child_bar = progress_bar(self.train_dataloader,parent = parent_bar)\n            self.model.train()\n            \n            for train_images,train_labels in child_bar:\n                train_images,train_labels = train_images.to(self.device),train_labels.to(self.device)\n                optimizer.zero_grad(set_to_none = True)\n                probs = self.model(train_images)\n                loss = loss_fn(probs,train_labels)\n                train_batch_losses.append(round(loss.data.item() * train_images.shape[0],3))\n                _,labels = torch.max(probs,dim = 1)\n                train_samples += train_images.shape[0]\n                match_tensor = (labels == train_labels).float()\n                train_batch_acc.append(round(float(match_tensor.sum().item()),3))\n                loss.backward()\n                optimizer.step()\n                parent_bar.child.comment = f\"Train loss: {train_batch_losses[-1] / train_images.shape[0]}, train acc: {train_batch_acc[-1] / train_labels.shape[0]}\"\n            \n            train_batch_losses = round(sum(train_batch_losses) / train_samples,3)\n            train_batch_acc = round(sum(train_batch_acc) / train_samples,3)\n            \n            valid_batch_losses,valid_batch_acc = [],[]\n            valid_samples = 0\n            child_bar = progress_bar(self.valid_dataloader,parent = parent_bar)\n            self.model.eval()\n            \n            with torch.no_grad():\n                for valid_images,valid_labels in child_bar:\n                    valid_images,valid_labels = valid_images.to(self.device),valid_labels.to(self.device)\n                    probs = self.model(valid_images)\n                    loss = loss_fn(probs,valid_labels)\n                    valid_batch_losses.append(round(loss.item() * valid_images.shape[0],3))\n                    _,labels = torch.max(probs,dim = 1)\n                    valid_samples += valid_images.shape[0]\n                    match_tensor = (labels == valid_labels).float()\n                    valid_batch_acc.append(round(float(match_tensor.sum().item()),3))\n                    parent_bar.child.comment = f\"Valid loss: {valid_batch_losses[-1] / valid_images.shape[0]}, valid acc: {valid_batch_acc[-1] / valid_images.shape[0]}\"\n            \n            valid_batch_losses = round(sum(valid_batch_losses) / valid_samples,3)\n            valid_batch_acc = round(sum(valid_batch_acc) / valid_samples,3)\n            \n            parent_bar.write(f\"Epoch: {epoch + 1} / {epochs} -> Train loss: {train_batch_losses}, train acc: {train_batch_acc}, valid loss: {valid_batch_losses}, valid acc: {valid_batch_acc}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:44:16.565504Z","iopub.execute_input":"2024-05-26T17:44:16.565827Z","iopub.status.idle":"2024-05-26T17:44:16.583210Z","shell.execute_reply.started":"2024-05-26T17:44:16.565802Z","shell.execute_reply":"2024-05-26T17:44:16.582195Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"model = Resnet(image_size = image_size,num_classes = len(classes),num_conv = 3)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:46:59.385389Z","iopub.execute_input":"2024-05-26T17:46:59.386166Z","iopub.status.idle":"2024-05-26T17:46:59.731643Z","shell.execute_reply.started":"2024-05-26T17:46:59.386131Z","shell.execute_reply":"2024-05-26T17:46:59.730779Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(model,device,train_dataloader,valid_dataloader)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:46:59.733584Z","iopub.execute_input":"2024-05-26T17:46:59.734438Z","iopub.status.idle":"2024-05-26T17:46:59.785769Z","shell.execute_reply.started":"2024-05-26T17:46:59.734399Z","shell.execute_reply":"2024-05-26T17:46:59.784702Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"trainer.train(epochs = epochs)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:46:59.786936Z","iopub.execute_input":"2024-05-26T17:46:59.787235Z","iopub.status.idle":"2024-05-26T17:58:14.785207Z","shell.execute_reply.started":"2024-05-26T17:46:59.787210Z","shell.execute_reply":"2024-05-26T17:58:14.784348Z"},"trusted":true},"execution_count":36,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Epoch: 1 / 10 -> Train loss: 1.091, train acc: 0.956, valid loss: 1.058, valid acc: 0.986<p>Epoch: 2 / 10 -> Train loss: 1.053, train acc: 0.991, valid loss: 1.049, valid acc: 0.995<p>Epoch: 3 / 10 -> Train loss: 1.052, train acc: 0.991, valid loss: 1.046, valid acc: 0.998<p>Epoch: 4 / 10 -> Train loss: 1.051, train acc: 0.993, valid loss: 1.047, valid acc: 0.997<p>Epoch: 5 / 10 -> Train loss: 1.049, train acc: 0.994, valid loss: 1.046, valid acc: 0.998<p>Epoch: 6 / 10 -> Train loss: 1.05, train acc: 0.994, valid loss: 1.047, valid acc: 0.996<p>Epoch: 7 / 10 -> Train loss: 1.05, train acc: 0.993, valid loss: 1.047, valid acc: 0.997<p>Epoch: 8 / 10 -> Train loss: 1.049, train acc: 0.995, valid loss: 1.047, valid acc: 0.996<p>Epoch: 9 / 10 -> Train loss: 1.05, train acc: 0.994, valid loss: 1.046, valid acc: 0.997<p>Epoch: 10 / 10 -> Train loss: 1.049, train acc: 0.995, valid loss: 1.047, valid acc: 0.997"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  return self._call_impl(*args, **kwargs)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}